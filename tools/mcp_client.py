"""
Fashion AI Automation System - MCP (Model Context Protocol) Client
"""

import json
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

from config.settings import settings


class MCPClient:
    """MCP(Model Context Protocol) ê¸°ë°˜ LLM í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            api_key = settings.openai_api_key
            if not api_key:
                try:
                    import streamlit as st
                    api_key = st.secrets.get("OPENAI_API_KEY", "")
                except:
                    pass
            
            self.llm = ChatOpenAI(
                model=settings.openai_model,
                temperature=settings.openai_temperature,
                max_tokens=settings.max_tokens,
                api_key=api_key
            )
            
            # MCP ë„êµ¬ ë“±ë¡
            self.available_tools = self._register_tools()
            
        except Exception as e:
            print(f"MCPClient ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            self.llm = None
            self.available_tools = {}
    
    def _register_tools(self) -> Dict[str, Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì„ MCP í˜•ì‹ìœ¼ë¡œ ë“±ë¡"""
        
        tools = {
            "trend_analyzer": {
                "name": "trend_analyzer",
                "description": "íŒ¨ì…˜ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ë„êµ¬",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "data": {
                            "type": "string",
                            "description": "ë¶„ì„í•  íŠ¸ë Œë“œ ë°ì´í„°"
                        },
                        "analysis_type": {
                            "type": "string",
                            "enum": ["trend_summary", "seasonal_analysis", "brand_comparison"],
                            "description": "ë¶„ì„ ìœ í˜•"
                        },
                        "target_audience": {
                            "type": "string",
                            "description": "íƒ€ê²Ÿ ê³ ê°ì¸µ"
                        }
                    },
                    "required": ["data", "analysis_type"]
                }
            },
            
            "sentiment_analyzer": {
                "name": "sentiment_analyzer",
                "description": "ì†Œë¹„ì ë¦¬ë·°, SNS ëŒ“ê¸€ ë“±ì˜ ê°ì„±ì„ ë¶„ì„í•˜ëŠ” ë„êµ¬",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "text_data": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸"
                        },
                        "context": {
                            "type": "string",
                            "description": "ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ (ì œí’ˆ, ë¸Œëœë“œ ë“±)"
                        }
                    },
                    "required": ["text_data"]
                }
            },
            
            "content_generator": {
                "name": "content_generator",
                "description": "ë§ˆì¼€íŒ… ì½˜í…ì¸ , ì œí’ˆ ê¸°íšì„œ ë“±ì„ ìƒì„±í•˜ëŠ” ë„êµ¬",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "content_type": {
                            "type": "string",
                            "enum": ["product_proposal", "marketing_copy", "social_content", "blog_post"],
                            "description": "ìƒì„±í•  ì½˜í…ì¸  ìœ í˜•"
                        },
                        "input_data": {
                            "type": "object",
                            "description": "ì½˜í…ì¸  ìƒì„±ì— í•„ìš”í•œ ì…ë ¥ ë°ì´í„°"
                        },
                        "style": {
                            "type": "string",
                            "description": "ì½˜í…ì¸  ìŠ¤íƒ€ì¼ (formal, casual, trendy ë“±)"
                        }
                    },
                    "required": ["content_type", "input_data"]
                }
            },
            
            "data_collector": {
                "name": "data_collector",
                "description": "ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ íŒ¨ì…˜ ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ë„êµ¬",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "source_type": {
                            "type": "string",
                            "enum": ["naver_shopping", "web_scraping", "social_media"],
                            "description": "ë°ì´í„° ì†ŒìŠ¤ ìœ í˜•"
                        },
                        "keywords": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ"
                        },
                        "limit": {
                            "type": "integer",
                            "default": 10,
                            "description": "ìˆ˜ì§‘í•  ë°ì´í„° ê°œìˆ˜"
                        }
                    },
                    "required": ["source_type", "keywords"]
                }
            }
        }
        
        return tools
    
    def call_tool(self, tool_name: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """MCP ë„êµ¬ í˜¸ì¶œ"""
        
        try:
            if tool_name not in self.available_tools:
                return {
                    "success": False,
                    "error": f"ë„êµ¬ '{tool_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "available_tools": list(self.available_tools.keys())
                }
            
            # ë„êµ¬ë³„ ì‹¤í–‰ ë¡œì§
            if tool_name == "trend_analyzer":
                return self._execute_trend_analyzer(parameters)
            elif tool_name == "sentiment_analyzer":
                return self._execute_sentiment_analyzer(parameters)
            elif tool_name == "content_generator":
                return self._execute_content_generator(parameters)
            elif tool_name == "data_collector":
                return self._execute_data_collector(parameters)
            else:
                return {
                    "success": False,
                    "error": f"ë„êµ¬ '{tool_name}'ì˜ ì‹¤í–‰ ë¡œì§ì´ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }
                
        except Exception as e:
            return {
                "success": False,
                "error": f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def _execute_trend_analyzer(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """íŠ¸ë Œë“œ ë¶„ì„ ë„êµ¬ ì‹¤í–‰"""
        
        try:
            data = parameters.get("data", "")
            analysis_type = parameters.get("analysis_type", "trend_summary")
            target_audience = parameters.get("target_audience", "ì¼ë°˜ ì†Œë¹„ì")
            
            # ë¶„ì„ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
            prompts = {
                "trend_summary": f"""ë‹¤ìŒ íŒ¨ì…˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:

ë°ì´í„°: {data}
íƒ€ê²Ÿ ê³ ê°: {target_audience}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. ì£¼ìš” íŠ¸ë Œë“œ (3-5ê°œ)
2. íƒ€ê²Ÿ ê³ ê°ë³„ ì¸ì‚¬ì´íŠ¸
3. ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œì¥ì‚¬í•­""",

                "seasonal_analysis": f"""ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„ì ˆë³„ íŒ¨ì…˜ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

ë°ì´í„°: {data}
íƒ€ê²Ÿ ê³ ê°: {target_audience}

ê³„ì ˆë³„ íŠ¹ì§•ê³¼ ë³€í™” íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.""",

                "brand_comparison": f"""ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸Œëœë“œë³„ í¬ì§€ì…”ë‹ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ë°ì´í„°: {data}
íƒ€ê²Ÿ ê³ ê°: {target_audience}

ë¸Œëœë“œë³„ ì°¨ë³„ì ê³¼ ì‹œì¥ í¬ì§€ì…˜ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."""
            }
            
            prompt = prompts.get(analysis_type, prompts["trend_summary"])
            
            # LLM í˜¸ì¶œ
            if self.llm:
                messages = [
                    SystemMessage(content="ë‹¹ì‹ ì€ íŒ¨ì…˜ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                    HumanMessage(content=prompt)
                ]
                
                response = self.llm.invoke(messages)
                
                return {
                    "success": True,
                    "tool_name": "trend_analyzer",
                    "analysis_type": analysis_type,
                    "result": response.content,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return self._get_sample_trend_analysis(analysis_type)
                
        except Exception as e:
            return {
                "success": False,
                "error": f"íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            }
    
    def _execute_sentiment_analyzer(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ê°ì„± ë¶„ì„ ë„êµ¬ ì‹¤í–‰"""
        
        try:
            text_data = parameters.get("text_data", [])
            context = parameters.get("context", "íŒ¨ì…˜ ì œí’ˆ")
            
            if not text_data:
                return {
                    "success": False,
                    "error": "ë¶„ì„í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # í…ìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬
            formatted_texts = "\n".join([f"- {text}" for text in text_data[:10]])  # ìµœëŒ€ 10ê°œ
            
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë“¤ì˜ ê°ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸: {context}

í…ìŠ¤íŠ¸ ë°ì´í„°:
{formatted_texts}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. ì „ì²´ ê°ì„± ì ìˆ˜ (-1.0 ~ 1.0)
2. ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ë¹„ìœ¨
3. ì£¼ìš” ê°ì • í‚¤ì›Œë“œ
4. ê°œì„ ì  ì œì•ˆ"""
            
            # LLM í˜¸ì¶œ
            if self.llm:
                messages = [
                    SystemMessage(content="ë‹¹ì‹ ì€ ì†Œë¹„ì ê°ì„± ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                    HumanMessage(content=prompt)
                ]
                
                response = self.llm.invoke(messages)
                
                return {
                    "success": True,
                    "tool_name": "sentiment_analyzer",
                    "context": context,
                    "analyzed_count": len(text_data),
                    "result": response.content,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return self._get_sample_sentiment_analysis()
                
        except Exception as e:
            return {
                "success": False,
                "error": f"ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            }
    
    def _execute_content_generator(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ì½˜í…ì¸  ìƒì„± ë„êµ¬ ì‹¤í–‰"""
        
        try:
            content_type = parameters.get("content_type", "marketing_copy")
            input_data = parameters.get("input_data", {})
            style = parameters.get("style", "professional")
            
            # ì½˜í…ì¸  ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
            prompts = {
                "product_proposal": f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œí’ˆ ê¸°íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì…ë ¥ ë°ì´í„°: {json.dumps(input_data, ensure_ascii=False, indent=2)}
ìŠ¤íƒ€ì¼: {style}

ì œí’ˆ ê¸°íšì„œ í˜•ì‹:
1. ì œí’ˆëª… ë° ì»¨ì…‰
2. íƒ€ê²Ÿ ê³ ê° í˜ë¥´ì†Œë‚˜
3. ì£¼ìš” íŠ¹ì§• ë° ì°¨ë³„ì 
4. ê°€ê²© ì „ëµ
5. ë§ˆì¼€íŒ… í¬ì¸íŠ¸""",

                "marketing_copy": f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆì¼€íŒ… ë¬¸êµ¬ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì…ë ¥ ë°ì´í„°: {json.dumps(input_data, ensure_ascii=False, indent=2)}
ìŠ¤íƒ€ì¼: {style}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
1. ë©”ì¸ ìºì¹˜í”„ë ˆì´ì¦ˆ (20ì ì´ë‚´)
2. ì„œë¸Œ ì¹´í”¼ (50ì ì´ë‚´)
3. ìƒì„¸ ì„¤ëª… (100ì ì´ë‚´)
4. í•´ì‹œíƒœê·¸ (5ê°œ)""",

                "social_content": f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ SNS ì½˜í…ì¸ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì…ë ¥ ë°ì´í„°: {json.dumps(input_data, ensure_ascii=False, indent=2)}
ìŠ¤íƒ€ì¼: {style}

SNS í¬ìŠ¤íŒ…ìš© í…ìŠ¤íŠ¸ì™€ í•´ì‹œíƒœê·¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.""",

                "blog_post": f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ì…ë ¥ ë°ì´í„°: {json.dumps(input_data, ensure_ascii=False, indent=2)}
ìŠ¤íƒ€ì¼: {style}

ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ êµ¬ì¡°:
1. ì œëª©
2. ì„œë¡ 
3. ë³¸ë¡  (3-4ê°œ ì„¹ì…˜)
4. ê²°ë¡ """
            }
            
            prompt = prompts.get(content_type, prompts["marketing_copy"])
            
            # LLM í˜¸ì¶œ
            if self.llm:
                messages = [
                    SystemMessage(content="ë‹¹ì‹ ì€ íŒ¨ì…˜ ë§ˆì¼€íŒ… ì½˜í…ì¸  ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                    HumanMessage(content=prompt)
                ]
                
                response = self.llm.invoke(messages)
                
                return {
                    "success": True,
                    "tool_name": "content_generator",
                    "content_type": content_type,
                    "style": style,
                    "result": response.content,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return self._get_sample_content_generation(content_type)
                
        except Exception as e:
            return {
                "success": False,
                "error": f"ì½˜í…ì¸  ìƒì„± ì˜¤ë¥˜: {str(e)}"
            }
    
    def _execute_data_collector(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬ ì‹¤í–‰"""
        
        try:
            source_type = parameters.get("source_type", "naver_shopping")
            keywords = parameters.get("keywords", [])
            limit = parameters.get("limit", 10)
            
            if not keywords:
                return {
                    "success": False,
                    "error": "ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í•´ë‹¹ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘
            # ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
            collected_data = self._get_sample_collected_data(source_type, keywords, limit)
            
            return {
                "success": True,
                "tool_name": "data_collector",
                "source_type": source_type,
                "keywords": keywords,
                "collected_count": len(collected_data),
                "result": collected_data,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}"
            }
    
    def _get_sample_trend_analysis(self, analysis_type: str) -> Dict[str, Any]:
        """ìƒ˜í”Œ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼"""
        
        analyses = {
            "trend_summary": """
ì£¼ìš” íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼:

1. ì§€ì†ê°€ëŠ¥í•œ íŒ¨ì…˜
   - ì¹œí™˜ê²½ ì†Œì¬ ì‚¬ìš© ì¦ê°€
   - ì—…ì‚¬ì´í´ë§ ì œí’ˆ ê´€ì‹¬ ìƒìŠ¹

2. ë¯¸ë‹ˆë©€ ë””ìì¸
   - ì‹¬í”Œí•˜ê³  ê¸°ëŠ¥ì ì¸ ë””ìì¸ ì„ í˜¸
   - ì¤‘ì„±ì ì¸ ì»¬ëŸ¬ íŒ”ë ˆíŠ¸

3. í¸ì•ˆí•¨ ìš°ì„ 
   - ì¬íƒê·¼ë¬´ ì¦ê°€ë¡œ í¸ì•ˆí•œ ì˜ë¥˜ ì„ í˜¸
   - ì•„ì›ƒë„ì–´ ìŠ¤íƒ€ì¼ì˜ ì¼ìƒí™”

ì‹¤í–‰ ê¶Œì¥ì‚¬í•­:
- ì¹œí™˜ê²½ ì†Œì¬ ë¼ì¸ ê°œë°œ
- ë‹¤ëª©ì  í™œìš© ê°€ëŠ¥í•œ ì•„ì´í…œ ê¸°íš
""",
            "seasonal_analysis": "ê³„ì ˆë³„ ë¶„ì„: ì—¬ë¦„ì²  ë¦°ë„¨ ì†Œì¬ì™€ ë°ì€ ì»¬ëŸ¬ê°€ ì£¼ìš” íŠ¸ë Œë“œ",
            "brand_comparison": "ë¸Œëœë“œ ë¹„êµ: í”„ë¦¬ë¯¸ì—„ ë¸Œëœë“œëŠ” í’ˆì§ˆê³¼ ë””ìì¸, íŒ¨ìŠ¤íŠ¸íŒ¨ì…˜ì€ ê°€ê²© ê²½ìŸë ¥ ì¤‘ì‹¬"
        }
        
        return {
            "success": True,
            "tool_name": "trend_analyzer",
            "analysis_type": analysis_type,
            "result": analyses.get(analysis_type, analyses["trend_summary"]),
            "timestamp": datetime.now().isoformat(),
            "note": "ìƒ˜í”Œ ë°ì´í„° (LLM ì—°ê²° ë¶ˆê°€)"
        }
    
    def _get_sample_sentiment_analysis(self) -> Dict[str, Any]:
        """ìƒ˜í”Œ ê°ì„± ë¶„ì„ ê²°ê³¼"""
        
        return {
            "success": True,
            "tool_name": "sentiment_analyzer",
            "result": """
ê°ì„± ë¶„ì„ ê²°ê³¼:

1. ì „ì²´ ê°ì„± ì ìˆ˜: 0.6 (ê¸ì •ì )
2. ê°ì„± ë¶„í¬:
   - ê¸ì •: 65%
   - ì¤‘ë¦½: 25%  
   - ë¶€ì •: 10%

3. ì£¼ìš” ê°ì • í‚¤ì›Œë“œ:
   - ë§Œì¡±, ì˜ˆì˜ë‹¤, í¸ì•ˆí•˜ë‹¤, íŠ¸ë Œë””í•˜ë‹¤

4. ê°œì„ ì :
   - ì‚¬ì´ì¦ˆ ê°€ì´ë“œ ë³´ì™„ í•„ìš”
   - ë°°ì†¡ ì†ë„ ê°œì„  ìš”êµ¬
""",
            "timestamp": datetime.now().isoformat(),
            "note": "ìƒ˜í”Œ ë°ì´í„° (LLM ì—°ê²° ë¶ˆê°€)"
        }
    
    def _get_sample_content_generation(self, content_type: str) -> Dict[str, Any]:
        """ìƒ˜í”Œ ì½˜í…ì¸  ìƒì„± ê²°ê³¼"""
        
        contents = {
            "product_proposal": """
ì œí’ˆ ê¸°íšì„œ:

1. ì œí’ˆëª…: ì—ì½” ë¦°ë„¨ ì…”ì¸ 
2. ì»¨ì…‰: ì§€ì†ê°€ëŠ¥í•œ ì—¬ë¦„ ê¸°ë³¸í…œ
3. íƒ€ê²Ÿ: 20-30ëŒ€ í™˜ê²½ ì˜ì‹ ìˆëŠ” ì—¬ì„±
4. íŠ¹ì§•: 100% ì˜¤ê°€ë‹‰ ë¦°ë„¨, ë¯¸ë‹ˆë©€ ë””ìì¸
5. ê°€ê²©: 89,000ì›
""",
            "marketing_copy": """
ë§ˆì¼€íŒ… ë¬¸êµ¬:

1. ë©”ì¸ ì¹´í”¼: "ìì—°ì´ ë§Œë“  í¸ì•ˆí•¨"
2. ì„œë¸Œ ì¹´í”¼: "100% ì˜¤ê°€ë‹‰ ë¦°ë„¨ìœ¼ë¡œ ë§Œë“  í”„ë¦¬ë¯¸ì—„ ì…”ì¸ "
3. ìƒì„¸ ì„¤ëª…: "ì§€êµ¬ë¥¼ ìƒê°í•˜ëŠ” ë§ˆìŒê³¼ í¸ì•ˆí•¨ì„ ë™ì‹œì—"
4. í•´ì‹œíƒœê·¸: #ì—ì½”íŒ¨ì…˜ #ë¦°ë„¨ì…”ì¸  #ì§€ì†ê°€ëŠ¥ #ë¯¸ë‹ˆë©€ #ì—¬ë¦„ë£©
""",
            "social_content": "ì˜¤ëŠ˜ì˜ #OOTD ğŸŒ¿ ìì—°ìŠ¤ëŸ¬ìš´ ë¦°ë„¨ ì…”ì¸ ë¡œ ì™„ì„±í•œ ì—ì½” ìŠ¤íƒ€ì¼ë§",
            "blog_post": "2024 ì—¬ë¦„, ì§€ì†ê°€ëŠ¥í•œ íŒ¨ì…˜ì´ íŠ¸ë Œë“œì¸ ì´ìœ "
        }
        
        return {
            "success": True,
            "tool_name": "content_generator",
            "content_type": content_type,
            "result": contents.get(content_type, contents["marketing_copy"]),
            "timestamp": datetime.now().isoformat(),
            "note": "ìƒ˜í”Œ ë°ì´í„° (LLM ì—°ê²° ë¶ˆê°€)"
        }
    
    def _get_sample_collected_data(self, source_type: str, keywords: List[str], limit: int) -> List[Dict[str, Any]]:
        """ìƒ˜í”Œ ìˆ˜ì§‘ ë°ì´í„°"""
        
        sample_data = []
        keyword = keywords[0] if keywords else "íŒ¨ì…˜"
        
        for i in range(min(limit, 3)):
            if source_type == "naver_shopping":
                sample_data.append({
                    "title": f"{keyword} ìƒí’ˆ {i+1}",
                    "price": f"{50000 + i*10000}",
                    "brand": f"ë¸Œëœë“œ{i+1}",
                    "link": f"https://example.com/product{i+1}"
                })
            elif source_type == "web_scraping":
                sample_data.append({
                    "title": f"{keyword} íŠ¸ë Œë“œ ê¸°ì‚¬ {i+1}",
                    "content": f"{keyword}ì— ëŒ€í•œ ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„...",
                    "source": f"íŒ¨ì…˜ë§¤ê±°ì§„{i+1}",
                    "url": f"https://example.com/article{i+1}"
                })
            elif source_type == "social_media":
                sample_data.append({
                    "platform": "instagram",
                    "content": f"#{keyword} ì˜¤ëŠ˜ì˜ ìŠ¤íƒ€ì¼ë§ âœ¨",
                    "likes": 150 + i*50,
                    "comments": 20 + i*5
                })
        
        return sample_data
    
    def get_available_tools(self) -> Dict[str, Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜"""
        return self.available_tools
    
    def is_tool_available(self, tool_name: str) -> bool:
        """íŠ¹ì • ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return tool_name in self.available_tools
    
    def execute_workflow(self, workflow_steps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ì›Œí¬í”Œë¡œìš°"""
        
        results = []
        
        for step in workflow_steps:
            tool_name = step.get("tool")
            parameters = step.get("parameters", {})
            
            result = self.call_tool(tool_name, parameters)
            results.append({
                "step": step,
                "result": result,
                "timestamp": datetime.now().isoformat()
            })
            
            # ì´ì „ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ì— ì „ë‹¬ (í•„ìš”í•œ ê²½ìš°)
            if result.get("success") and len(workflow_steps) > 1:
                # ê²°ê³¼ë¥¼ ë‹¤ìŒ ë‹¨ê³„ì˜ íŒŒë¼ë¯¸í„°ì— ì¶”ê°€í•  ìˆ˜ ìˆìŒ
                pass
        
        return results
    
    def get_sample_trend_analysis(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ íŠ¸ë Œë“œ ë¶„ì„ ë°˜í™˜"""
        sample_analysis = self._get_sample_trend_analysis("trend_summary")
        return {
            "main_trends": [
                "ì§€ì†ê°€ëŠ¥í•œ íŒ¨ì…˜ í™•ì‚°",
                "ë¯¸ë‹ˆë©€ ë””ìì¸ ì„ í˜¸",
                "í¸ì•ˆí•¨ ìš°ì„  íŠ¸ë Œë“œ",
                "Y2K ë³µê³  ê°ì„±",
                "ë¹„ë¹„ë“œ ì»¬ëŸ¬ ì¸ê¸°"
            ],
            "predictions": [
                "ì¹œí™˜ê²½ ì†Œì¬ ì‚¬ìš© ì¦ê°€",
                "ë©€í‹° ê¸°ëŠ¥ì„± ì•„ì´í…œ ì¸ê¸°", 
                "ê°œì„± í‘œí˜„ ì•„ì´í…œ í™•ì‚°"
            ],
            "business_suggestions": [
                "ì§€ì†ê°€ëŠ¥ì„± ë§ˆì¼€íŒ… ê°•í™”",
                "í¸ì˜ì„± ì¤‘ì‹¬ ì œí’ˆ ê°œë°œ",
                "ê°œì„± ë§ì¶¤ ì„œë¹„ìŠ¤ ì œê³µ"
            ],
            "full_analysis": sample_analysis["result"]
        }
    
    def get_sample_sentiment_analysis(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ê°ì„± ë¶„ì„ ë°˜í™˜"""
        return self._get_sample_sentiment_analysis()
    
    def get_sample_content_generation(self, content_type: str = "marketing_copy") -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì½˜í…ì¸  ìƒì„± ë°˜í™˜"""
        return self._get_sample_content_generation(content_type)
    
    def is_connected(self) -> bool:
        """MCP í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìƒíƒœ í™•ì¸"""
        return self.llm is not None 